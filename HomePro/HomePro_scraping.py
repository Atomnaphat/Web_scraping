from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from bs4 import BeautifulSoup
import time
import pymongo
from datetime import datetime

# --- ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Selenium ---
options = Options()
options.add_argument('--headless')
options.add_argument('--disable-gpu')
driver = webdriver.Chrome(options=options)

# --- MongoDB ---
client = pymongo.MongoClient("mongodb://localhost:27017/")
db = client["scraping_db"]
collection = db["Homepro_logs"]

# --- ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏µ‡πà‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà ---
url = "https://www.homepro.co.th/c/CON"  # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡∏ó‡πà‡∏≠/‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏õ‡∏£‡∏∞‡∏õ‡∏≤
driver.get(url)
time.sleep(5)

# --- ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ---
SCROLL_PAUSE_TIME = 2
last_height = driver.execute_script("return document.body.scrollHeight")
while True:
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    time.sleep(SCROLL_PAUSE_TIME)
    new_height = driver.execute_script("return document.body.scrollHeight")
    if new_height == last_height:
        break
    last_height = new_height

soup = BeautifulSoup(driver.page_source, 'html.parser')
products = soup.find_all('div', class_='product-card-mkp-s2')

data = []

print(f"‡∏û‡∏ö‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(products)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")

for product in products:
    try:
        link_tag = product.find('a', href=True)
        if not link_tag:
            continue
        product_url = link_tag['href']
        if not product_url.startswith("http"):
            product_url = f"https://www.homepro.co.th{product_url}"

        # üëâ ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏ô‡πâ‡∏≤
        driver.get(product_url)
        time.sleep(2)
        product_soup = BeautifulSoup(driver.page_source, 'html.parser')

        # ‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤
        title_tag = product_soup.find('h1')
        title = title_tag.get_text(strip=True) if title_tag else "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠"

        # ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤
        price_tag = product_soup.find('div', class_='discount-price')
        price = price_tag.get_text(strip=True) if price_tag else "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏Ñ‡∏≤"

        # ‡∏î‡∏∂‡∏á‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô /‡∏°‡πâ‡∏ß‡∏ô (contain 30 ‡πÄ‡∏°‡∏ï‡∏£)
        unit_tag = product_soup.find('div', class_='span.product-unit')
        unit = unit_tag.get_text(strip=True) if unit_tag else "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏´‡∏ô‡πà‡∏ß‡∏¢"

        # print(f"‚úÖ {title} | {price} | {product_url}")

        data.append({
            "title": title,
            "price": price,
            "link": product_url,
            "scraped_at": datetime.utcnow()
        })

        collection.insert_one(data[-1])

    except Exception as e:
        print(f"‚ö†Ô∏è ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")

driver.quit()
print(f"\n‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(data)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
